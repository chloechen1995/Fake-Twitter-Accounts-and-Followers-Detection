{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest output a list of features that are important in predicting the variable.\n",
    "\n",
    "* Perform both regression and classification tasks\n",
    "* Develop decision trees based on random selection of data and variables\n",
    "* Use averaging to improve the predictive accuracy and control over-fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does it work?\n",
    "\n",
    "Assume we have Data = {(X1, Y1), ... (Xn, Yn)}:\n",
    "\n",
    "For b (Single Tree) = 1 to B (Random Forest):\n",
    "    \n",
    "    1) Draw a bootstrap sample X* of size N from the training data\n",
    "    \n",
    "    2) Grow a random-forest tree Tb to the bootstrapped data, repeat the following steps until the minimum node size $\\n_{min}$ is reached.\n",
    "        i. Select m variables at random from the p variables\n",
    "        ii. Pick the best variable/split-point among the m\n",
    "        iii. Split the node into two daughter nodes\n",
    "Output the ensemble of trees {Tb}\n",
    "    \n",
    "    1) In the forest with T trees where we have t \\episilon {1, ..., T}\n",
    "    2) All the trees are trained independently\n",
    "    3) During testing, each test point v is simultaneously pushed through all trees(starting at the root) until it reaches the corresponding leaves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forests of randomized trees\n",
    "* Forest classifiers have to be fitted with two arrays:\n",
    "    \n",
    "    1) A sparse or dense array X of size [n_samples, n_features] for the training samples\n",
    "    \n",
    "    2) An array Y of size [n_samples] for the target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X = [[1, 0, 2], [3, 6, 1], [0, 2, 4], [8, 9, 0], [5, 5, 1]]\n",
    "Y = [0, 1, 0, 1, 0]\n",
    "# n_estimators: number of trees in the forest\n",
    "clf = RandomForestClassifier(n_estimators = 10)\n",
    "clf = clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference:\n",
    "https://www.youtube.com/watch?v=3kYujfDgmNk\n",
    "\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "Random Forest Classifier\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

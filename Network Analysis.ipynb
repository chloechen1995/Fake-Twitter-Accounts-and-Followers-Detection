{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating a Network Analysis of Twitter Followers\n",
    "## Collect Followers Data From Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import requests_cache\n",
    "requests_cache.install_cache('nw_cache')\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---------- Read In Data\n",
    "# load in genuine accounts data\n",
    "genuine = pd.read_csv(open('./User dataset/genuine account.csv', 'rU'), \n",
    "                      encoding = 'utf-8', usecols = ['id'] )\n",
    "\n",
    "# load in fake accounts data\n",
    "path =r'./User dataset/fake data/'\n",
    "allFiles = glob.glob(path + \"/*.csv\")\n",
    "fake = pd.DataFrame()\n",
    "list_ = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(open(file_, 'rU'), encoding = 'utf-8', usecols = ['id'])\n",
    "    list_.append(df)\n",
    "fake = pd.concat(list_)\n",
    "\n",
    "# merge all the data \n",
    "all_ids = pd.concat([genuine, fake])\n",
    "\n",
    "# test set\n",
    "test_ids = all_ids.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---------- Twitter API setup\n",
    "CONSUMER_KEY = 'QifrSmYAQ2mjIf8kiPoL2kI4v'\n",
    "CONSUMER_SECRET = 'qHXPmXDd4Gw2cqZ5zKmDpU6drKEHTF396pj9qyoUYWDcLsFOlm'\n",
    "ACCESS_TOKEN = '3379234805-hUmhUJa0oV9V1mnKDuB6bitJ1QTEjdq2c9zE0RA'\n",
    "ACCESS_TOKEN_SECRET = 'cQiqDWDuoLj8SH68d6JuPhthToImk3WzmcQ3pbyxYfYK1'\n",
    "\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True) # wait_on_rate_limit=True: not return the 402 error code from twitter \n",
    "                                                # and wait the needed time to resume the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ---------- Set up Edges of Network\n",
    "def network_edges(G, user_id, filename):\n",
    "    followers = api.followers_ids(id = user_id)\n",
    "    followings = api.friends_ids(id = user_id)\n",
    "    \n",
    "    for follower in followers:\n",
    "        try:\n",
    "            G.add_edge(follower, user_id, weight = api.get_user(id = follower).followers_count)\n",
    "            # the speed is limited by Twitter API\n",
    "        except tweepy.TweepError: # the account may be suspended or deleted\n",
    "            pass\n",
    "    \n",
    "    for following in followings:\n",
    "        try:\n",
    "            G.add_edge(user_id, following, weight = api.get_user(id = following).followers_count)\n",
    "        except tweepy.TweepError:\n",
    "            pass\n",
    "    nx.write_gexf(G, filename, encoding='utf-8', prettyprint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---------- Build Networks of Relationships\n",
    "twitter_sphere = nx.DiGraph()\n",
    "\n",
    "for id in test_ids.id:\n",
    "    network_edges(twitter_sphere, id, 'test.gexf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Clustering Coefficient    \n",
    "The local clustering coefficient of a vertex in a graph quantifies how close its neighbours are to being a complete graph. It is the proportion of links between the vertices within its neighbourhood devided by the number of links that could possibly exit between them.    \n",
    "For a graph $G=(V,E)$ consisting of a set of vertices $V$ and a set of edges $E$, the neighbourhood $N_i$ for a vertex $v_i$ is defined as its immediately connected neighbours as follows:\n",
    "$$N_i=\\{v_j:e_{ij}\\in E \\vee e_{ji}\\in E\\}$$\n",
    "The local clustering coefficient for directed graphs is given as\n",
    "$$C_i=\\frac{|\\{e_{jk}:v_j, v_k\\in N_i,\\ e_{jk}\\in E\\}|}{k_i(k_i-1)}$$\n",
    "where $k_i$ is the number of neighbours of a vertex $v_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ---------- Local Clustering Coefficients\n",
    "def local_clustering_coef(G, node):\n",
    "    nbs = G.neighbors(node)\n",
    "    L = 0\n",
    "    for v in nbs:\n",
    "        for u in nbs:\n",
    "            if (v, u) in G.edges():\n",
    "                L += 1.0            \n",
    "    return L/(len(nbs)(len(nbs)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---------- Bi-directional links ratio\n",
    "def bi_dir_links_r(G, node):\n",
    "    nbs = G.neighbors(node)\n",
    "    N_bilink = 0\n",
    "    N_following = 0\n",
    "    for nb in nbs:\n",
    "        if (node, nb) in G.edges():\n",
    "            N_following += 1.0\n",
    "            if (nb, node) in G.edges():\n",
    "                N_bilink += 1.0\n",
    "    return N_bilink/N_following      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ---------- Analysis\n",
    "in_degree_ = twitter_sphere.in_degree()\n",
    "in_degree = {id: in_degree_[id] for id in test_ids.id}\n",
    "\n",
    "out_degree_ = twitter_sphere.out_degree()\n",
    "out_degree = {id: out_degree_[id] for id in test_ids.id}\n",
    "\n",
    "local_c = {id: local_clustering_coef(twitter_sphere, id) for id in test_ids.id}\n",
    "           \n",
    "bi_r = {id: bi_dir_links_r(twitter_sphere, id) for id in test_ids}\n",
    "\n",
    "df1 = pd.DataFrame_from_dict(in_degree, orient = 'index') \n",
    "df2 = pd.DataFrame_from_dict(out_degree, orient = 'index')\n",
    "df3 = pd.DataFrame_from_dict(local_c, orient = 'index')  \n",
    "df4 = pd.DataFrame_from_dict(bi_r, orient = 'index') \n",
    "\n",
    "final = pd.merge(pd.merge(pd.merge(pd.merge(df1, df2, on = 'id'), df3, on = 'id'), df4, on = 'id'), \n",
    "         test_ids, on = 'id')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
